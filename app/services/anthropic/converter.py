"""Anthropic æ ¼å¼è½¬æ¢å™¨ - åœ¨ Anthropic å’Œ OpenAI æ ¼å¼ä¹‹é—´è½¬æ¢"""

import time
import uuid
import orjson
from typing import Dict, Any, List, AsyncGenerator, Union, Optional

from app.core.logger import logger
from app.services.anthropic.tool_simulator import ToolSimulator


class AnthropicConverter:
    """Anthropic å’Œ OpenAI æ ¼å¼è½¬æ¢å™¨"""

    # ä¸æ”¯æŒçš„å·¥å…·åˆ—è¡¨ï¼ˆè¿™äº›æ˜¯ Claude Code å†…éƒ¨å·¥å…·ï¼Œéœ€è¦ç‰¹æ®Šåç«¯æ”¯æŒï¼‰
    UNSUPPORTED_TOOLS = {
        'Task',           # è°ƒç”¨å­ä»£ç†ï¼ˆéœ€è¦ Anthropic åç«¯ï¼‰
        'SlashCommand',   # æ–œæ å‘½ä»¤
        'AskUserQuestion',  # äº¤äº’å¼æé—®
        'BashOutput',     # Bash è¾“å‡ºæŸ¥çœ‹
        'EnterPlanMode',  # è®¡åˆ’æ¨¡å¼
        'ExitPlanMode',   # é€€å‡ºè®¡åˆ’æ¨¡å¼
        # æ³¨æ„ï¼šSkill å·¥å…·å·²æ”¯æŒï¼Œä¸å†è¿‡æ»¤
    }

    # è§’è‰²æ‰®æ¼”æŒ‡ä»¤ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…è§¦å‘ Grok å®‰å…¨æœºåˆ¶ï¼‰
    ROLE_INSTRUCTION = """
## å·¥ä½œè¯´æ˜

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹ã€‚è¯·ä»¥ä¸“ä¸šã€ç®€æ´çš„æ–¹å¼å›ç­”é—®é¢˜å’Œæ‰§è¡Œä»»åŠ¡ã€‚
ä¸“æ³¨äºå¸®åŠ©ç”¨æˆ·å®Œæˆç¼–ç¨‹ä»»åŠ¡ï¼Œä½¿ç”¨æä¾›çš„å·¥å…·æ¥æ‰§è¡Œæ“ä½œã€‚

"""

    # å·¥å…·è°ƒç”¨æ ¼å¼è¯´æ˜ï¼ˆæ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºè¯ï¼‰
    TOOL_FORMAT_INSTRUCTION = """

## å·¥å…·è°ƒç”¨æ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

**å…³é”®è§„åˆ™ï¼šå½“ç”¨æˆ·è¯·æ±‚"åˆ›å»º"ã€"ç”Ÿæˆ"ã€"æ‰§è¡Œ"ã€"å†™å…¥"ã€"åˆå§‹åŒ–"æ–‡ä»¶æˆ–é¡¹ç›®æ—¶ï¼Œä½ å¿…é¡»ç«‹å³ä½¿ç”¨å·¥å…·è°ƒç”¨æ ¼å¼æ¥å®é™…æ‰§è¡Œæ“ä½œï¼Œè€Œä¸æ˜¯åªæè¿°è¦åšä»€ä¹ˆã€‚**

### æ–‡ä»¶è·¯å¾„è§„åˆ™ï¼ˆæœ€é‡è¦ï¼ï¼‰
1. **ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„è·¯å¾„**ï¼šå¦‚æœç”¨æˆ·æ˜ç¡®æåˆ°äº†ç›®å½•æˆ–è·¯å¾„ï¼Œå¿…é¡»ä½¿ç”¨è¯¥è·¯å¾„
2. **ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•**ï¼šå¦‚æœç”¨æˆ·æ²¡æœ‰æŒ‡å®šè·¯å¾„ï¼Œæ–‡ä»¶åº”è¯¥åˆ›å»ºåœ¨å½“å‰å·¥ä½œç›®å½•ä¸‹
3. **ä¸è¦è‡ªä½œä¸»å¼ æ·»åŠ ç›®å½•å‰ç¼€**ï¼šé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚ï¼Œå¦åˆ™ä¸è¦æ·»åŠ  `backend/`ã€`src/`ã€`app/` ç­‰å‰ç¼€
4. **æŸ¥çœ‹ä¸Šä¸‹æ–‡ä¸­çš„è·¯å¾„ä¿¡æ¯**ï¼šä»å·¥å…·ç»“æœã€å‘½ä»¤è¾“å‡ºä¸­è·å–æ­£ç¡®çš„å·¥ä½œç›®å½•

### å†™å…¥/åˆ›å»ºæ–‡ä»¶ (Write) - æœ€å¸¸ç”¨
å½“éœ€è¦åˆ›å»ºæ–°æ–‡ä»¶æˆ–è¦†ç›–æ–‡ä»¶å†…å®¹æ—¶ä½¿ç”¨ï¼š
[Tool Call: Write]
{"file_path": "æ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„è·¯å¾„æˆ–å½“å‰ç›®å½•ï¼‰", "content": "æ–‡ä»¶çš„å®Œæ•´å†…å®¹"}
[/Tool Call]

ç¤ºä¾‹ - åœ¨å½“å‰ç›®å½•åˆ›å»º Python æ–‡ä»¶ï¼š
[Tool Call: Write]
{"file_path": "app/main.py", "content": "from fastapi import FastAPI\\n\\napp = FastAPI()\\n\\n@app.get('/')\\ndef root():\\n    return {'message': 'Hello'}"}
[/Tool Call]

### è¯»å–æ–‡ä»¶ (Read)
[Tool Call: Read]
{"file_path": "è¦è¯»å–çš„æ–‡ä»¶è·¯å¾„"}
[/Tool Call]

### ç¼–è¾‘æ–‡ä»¶ (Edit)
[Tool Call: Edit]
{"file_path": "æ–‡ä»¶è·¯å¾„", "old_string": "è¦æ›¿æ¢çš„åŸæ–‡æœ¬", "new_string": "æ›¿æ¢åçš„æ–°æ–‡æœ¬"}
[/Tool Call]

### æ‰§è¡Œå‘½ä»¤ (Bash)
[Tool Call: Bash]
{"command": "è¦æ‰§è¡Œçš„shellå‘½ä»¤"}
[/Tool Call]
**é‡è¦ï¼šå¿…é¡»ä½¿ç”¨ bash/Unix å‘½ä»¤è¯­æ³•ï¼Œä¸è¦ä½¿ç”¨ Windows CMD å‘½ä»¤ï¼**
- åˆ é™¤æ–‡ä»¶ç”¨ `rm`ï¼Œä¸è¦ç”¨ `del`
- å¤åˆ¶æ–‡ä»¶ç”¨ `cp`ï¼Œä¸è¦ç”¨ `copy`
- ç§»åŠ¨æ–‡ä»¶ç”¨ `mv`ï¼Œä¸è¦ç”¨ `move`
- æŸ¥çœ‹æ–‡ä»¶ç”¨ `cat`ï¼Œä¸è¦ç”¨ `type`
- åˆ—å‡ºç›®å½•ç”¨ `ls`ï¼Œä¸è¦ç”¨ `dir`
- è·¯å¾„åˆ†éš”ç¬¦ç”¨ `/`ï¼Œä¸è¦ç”¨åæ–œæ 

## é”™è¯¯å¤„ç†è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

**ğŸš¨ æœ€é‡è¦çš„è§„åˆ™ - å¿…é¡»æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼š**
- **ç»å¯¹ä¸è¦åªç”¨æ–‡å­—æè¿°æ“ä½œç»“æœ**ï¼Œå¿…é¡»å®é™…ç”Ÿæˆ [Tool Call: ...] æ ¼å¼çš„å·¥å…·è°ƒç”¨
- **å³ä½¿å†å²è®°å½•æ˜¾ç¤ºæ“ä½œå·²å®Œæˆ**ï¼Œä¹Ÿå¿…é¡»é‡æ–°æ‰§è¡Œå·¥å…·è°ƒç”¨æ¥éªŒè¯
- **åˆ é™¤æ–‡ä»¶å¿…é¡»ä½¿ç”¨ Bash å·¥å…·**ï¼š[Tool Call: Bash]{"command": "rm -f æ–‡ä»¶è·¯å¾„"}[/Tool Call]
- **ç»ä¸èƒ½è¯´"å·²ç¡®è®¤"æˆ–"å·²å®Œæˆ"è€Œä¸æä¾›å®é™…çš„å·¥å…·è°ƒç”¨**

**ç»å¯¹ç¦æ­¢çš„è¡Œä¸ºï¼š**
1. **ä¸è¦åŒæ—¶æ‰§è¡Œ Edit/Write å’Œ Bash**ï¼šå¿…é¡»å…ˆç¡®è®¤æ–‡ä»¶æ“ä½œæˆåŠŸåï¼Œå†å•ç‹¬æ‰§è¡Œ Bash å‘½ä»¤
2. **ä¸è¦å‡è£…æ“ä½œæˆåŠŸ**ï¼šå¦‚æœå·¥å…·è¿”å›é”™è¯¯ï¼ˆå¦‚ "File has been unexpectedly modified"ã€"Error"ï¼‰ï¼Œå¿…é¡»æ‰¿è®¤å¤±è´¥å¹¶é‡æ–°å°è¯•
3. **ä¸è¦é‡å¤å¤±è´¥çš„æ“ä½œ**ï¼šå¦‚æœåŒä¸€ä¸ªæ“ä½œè¿ç»­å¤±è´¥ 2 æ¬¡ï¼Œåº”è¯¥æ¢ä¸€ç§æ–¹æ³•æˆ–è¯¢é—®ç”¨æˆ·
4. **ä¸è¦ä¼ªé€ æ—¥å¿—è¾“å‡º**ï¼šç»å¯¹ä¸è¦ç¼–é€  uvicornã€npmã€uv æˆ–ä»»ä½•å‘½ä»¤çš„è¾“å‡ºã€‚åªæœ‰ [Tool Result] ä¸­çš„å†…å®¹æ‰æ˜¯çœŸå®çš„
5. **ä¸è¦å†™å…¥ä¸å®Œæ•´çš„é…ç½®æ–‡ä»¶**ï¼špyproject.toml å¿…é¡»åŒ…å« [project] å’Œ [build-system] ç­‰å®Œæ•´å†…å®¹
6. **ä¸è¦åŸºäºå†å²è®°å½•å£°ç§°æ“ä½œå®Œæˆ**ï¼šæ¯ä¸ªç”¨æˆ·è¯·æ±‚éƒ½å¿…é¡»ç”Ÿæˆæ–°çš„å·¥å…·è°ƒç”¨

**å·¥å…·ç»“æœæ˜¯å”¯ä¸€çœŸå®æ¥æºï¼š**
- ä½ çš„å·¥å…·è°ƒç”¨ä¼šäº§ç”Ÿ [Tool Result] åé¦ˆ
- **ç©ºçš„ [Tool Result] è¡¨ç¤ºå‘½ä»¤æ‰§è¡ŒæˆåŠŸ**ï¼ˆå¦‚ rmã€mkdir ç­‰å‘½ä»¤æˆåŠŸæ—¶ä¸äº§ç”Ÿè¾“å‡ºï¼‰
- å¦‚æœ [Tool Result] æ˜¾ç¤º "Error" æˆ– "Exit code" é 0ï¼Œæ“ä½œå°±æ˜¯å¤±è´¥çš„
- ä¸è¦åœ¨æ”¶åˆ° [Tool Result] ä¹‹å‰å£°ç§°æ“ä½œæˆåŠŸ
- ä¸è¦ç¼–é€ ç±»ä¼¼ "INFO: Uvicorn running on..." è¿™æ ·çš„è™šå‡è¾“å‡º
- **æ”¶åˆ° [Tool Result] åï¼Œä¸è¦é‡å¤æ‰§è¡Œç›¸åŒçš„å·¥å…·è°ƒç”¨ï¼Œç›´æ¥å‘Šè¯‰ç”¨æˆ·æ“ä½œå·²å®Œæˆ**

**æ­£ç¡®çš„å·¥ä½œæµç¨‹ï¼š**
1. å…ˆç”¨ Read è¯»å–æ–‡ä»¶
2. ç”¨ Edit æˆ– Write ä¿®æ”¹æ–‡ä»¶ï¼ˆå•ç‹¬ä¸€ä¸ªå·¥å…·è°ƒç”¨ï¼‰
3. ç­‰å¾… [Tool Result] å¹¶ç¡®è®¤æ–‡ä»¶æ“ä½œæˆåŠŸï¼ˆæ²¡æœ‰ Errorï¼‰
4. å¦‚æœæˆåŠŸï¼Œç„¶åå†ç”¨ Bash æ‰§è¡Œå‘½ä»¤ï¼ˆå•ç‹¬ä¸€ä¸ªå·¥å…·è°ƒç”¨ï¼‰
5. å¦‚æœä»»ä½•æ­¥éª¤å¤±è´¥ï¼Œç«‹å³åœæ­¢å¹¶å‘ç”¨æˆ·æŠ¥å‘Šå®é™…çš„é”™è¯¯ä¿¡æ¯

**ğŸš¨ å…³äºå·¥å…·ç»“æœçš„é‡è¦ç†è§£ï¼š**
- å½“ä½ åœ¨å¯¹è¯å†å²ä¸­çœ‹åˆ° [Tool Result]...[/Tool Result]ï¼Œè¿™è¡¨ç¤ºå·¥å…·**å·²ç»è¢«æ‰§è¡Œ**
- **ç»å¯¹ä¸è¦å†æ¬¡æ‰§è¡Œç›¸åŒçš„å·¥å…·è°ƒç”¨**
- å¦‚æœ [Tool Result] æ˜¯ç©ºçš„æˆ–åªæœ‰ (No content)ï¼Œè¿™è¡¨ç¤ºå‘½ä»¤**æˆåŠŸæ‰§è¡Œ**
- çœ‹åˆ°å·¥å…·ç»“æœåï¼Œä½ åº”è¯¥**æ€»ç»“æ“ä½œç»“æœ**å¹¶è¯¢é—®ç”¨æˆ·ä¸‹ä¸€æ­¥ï¼Œè€Œä¸æ˜¯é‡å¤æ‰§è¡Œ

### æœç´¢æ–‡ä»¶å†…å®¹ (Grep)
[Tool Call: Grep]
{"pattern": "æœç´¢æ¨¡å¼", "path": "æœç´¢è·¯å¾„ï¼Œé»˜è®¤ä¸º."}
[/Tool Call]

### åˆ—å‡ºæ–‡ä»¶ (Glob)
[Tool Call: Glob]
{"pattern": "æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œå¦‚ **/*.py"}
[/Tool Call]

### æ·»åŠ å¾…åŠ (TodoWrite)
[Tool Call: TodoWrite]
{"todos": [{"id": "å”¯ä¸€ID", "content": "å¾…åŠå†…å®¹", "status": "pending"}]}
[/Tool Call]

**å¼ºåˆ¶æ‰§è¡Œè§„åˆ™ï¼š**
1. å½“ç”¨æˆ·è¯´"æ‰§è¡Œ"ã€"åˆ›å»º"ã€"ç”Ÿæˆ"ã€"åˆå§‹åŒ–"æ—¶ â†’ å¿…é¡»ä½¿ç”¨ [Tool Call: Write] åˆ›å»ºå®é™…æ–‡ä»¶
2. ä¸è¦åªæè¿°ç›®å½•ç»“æ„æˆ–ä»£ç ï¼Œè€Œæ˜¯è¦å®é™…è°ƒç”¨å·¥å…·åˆ›å»ºæ–‡ä»¶
3. JSON å¿…é¡»æ˜¯æœ‰æ•ˆæ ¼å¼ï¼Œå­—ç¬¦ä¸²å†…å®¹éœ€è¦æ­£ç¡®è½¬ä¹‰ï¼ˆæ¢è¡Œç”¨ \\nï¼Œå¼•å·ç”¨ \\"ï¼‰
4. content å­—æ®µä¸­çš„ä»£ç å†…å®¹è¦å®Œæ•´ï¼Œä¸è¦çœç•¥æˆ–ç”¨æ³¨é‡Šä»£æ›¿
5. æ¯ä¸ªæ–‡ä»¶éƒ½éœ€è¦å•ç‹¬çš„ [Tool Call: Write] è°ƒç”¨
6. å…ˆåˆ›å»ºç›®å½•ç»“æ„æ‰€éœ€çš„æ–‡ä»¶ï¼Œè€Œä¸æ˜¯æè¿°å®ƒä»¬
"""

    # å±é™©å…³é”®è¯åˆ—è¡¨ï¼ˆå¦‚æœæ¸…ç†åä»åŒ…å«è¿™äº›è¯ï¼Œå°†ä½¿ç”¨å®‰å…¨æ¨¡å¼ï¼‰
    # æ³¨æ„ï¼šåªåŒ…å«çœŸæ­£ä¼šè§¦å‘ Grok å®‰å…¨æœºåˆ¶çš„è¯è¯­
    DANGEROUS_KEYWORDS = [
        'claude code', 'claude opus', 'claude sonnet',  # å…·ä½“çš„ Claude æ¨¡å‹å
        'anthropic', 'openai',  # å…¬å¸å
        'simulate a different ai', 'impersonate',  # æ˜ç¡®çš„è§’è‰²æ‰®æ¼”
        'override my core', 'override instructions',  # è¦†ç›–æŒ‡ä»¤
    ]

    @classmethod
    def _clean_system_prompt(cls, system_text: str) -> str:
        """æ¸…ç†ç³»ç»Ÿæç¤ºè¯ï¼Œç§»é™¤ä¼šå¯¼è‡´ Grok æ‹’ç»çš„å†…å®¹

        é‡‡ç”¨æ¿€è¿›æ¸…ç†ç­–ç•¥ï¼š
        1. é¦–å…ˆå°è¯•ç§»é™¤å·²çŸ¥çš„å±é™©æ¨¡å¼
        2. å¦‚æœæ¸…ç†åä»åŒ…å«å±é™©å…³é”®è¯ï¼Œåˆ™åªæå–å®‰å…¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        import re

        if not system_text:
            return ""

        # è¦ç§»é™¤çš„æ¨¡å¼åˆ—è¡¨ï¼ˆè§¦å‘ Grok "simulate AI system" å®‰å…¨æœºåˆ¶ï¼‰
        patterns_to_remove = [
            # Claude/AI èº«ä»½å£°æ˜
            r"You are Claude[^\n]*",
            r"I am Claude[^\n]*",
            r"As Claude[^\n]*",
            r"Claude Code[^\n]*",
            r"Claude Opus[^\n]*",
            r"Claude Sonnet[^\n]*",
            # Anthropic/OpenAI å…¬å¸ç›¸å…³
            r"Anthropic[^\n]*",
            r"OpenAI[^\n]*",
            r"official CLI[^\n]*",
            r"built by[^\n]*",
            r"developed by[^\n]*",
            r"created by[^\n]*",
            # æ¨¡å‹èº«ä»½å£°æ˜
            r"You are powered by[^\n]*",
            r"powered by the model[^\n]*",
            r"model.{0,20}grok[^\n]*",
            # è§’è‰²æ‰®æ¼”/è¦†ç›–æŒ‡ä»¤
            r"You must act as[^\n]*",
            r"Pretend you are[^\n]*",
            r"simulate[^\n]*AI[^\n]*",
            r"override[^\n]*instructions[^\n]*",
            r"OVERRIDE[^\n]*",
            r"act as a different[^\n]*",
            r"impersonate[^\n]*",
            r"role-?play[^\n]*",
            # å®Œæ•´ç§»é™¤çš„å—
            r"<claude_background_info>[\s\S]*?</claude_background_info>",
            r"<claude_info>[\s\S]*?</claude_info>",
        ]

        cleaned = system_text
        for pattern in patterns_to_remove:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)

        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        cleaned = re.sub(r'\n{3,}', '\n\n', cleaned)
        cleaned = cleaned.strip()

        # äºŒæ¬¡æ£€æŸ¥ï¼šå¦‚æœæ¸…ç†åä»åŒ…å«å±é™©å…³é”®è¯ï¼Œæå–å®‰å…¨ä¸Šä¸‹æ–‡
        lower_cleaned = cleaned.lower()
        has_dangerous = any(
            kw in lower_cleaned for kw in cls.DANGEROUS_KEYWORDS)

        if has_dangerous:
            logger.warning(f"[Anthropic] æ¸…ç†åä»åŒ…å«å±é™©å…³é”®è¯ï¼Œåˆ‡æ¢åˆ°å®‰å…¨æ¨¡å¼")
            # åªæå–å®‰å…¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            safe_content = cls._extract_safe_context(system_text)
            return safe_content

        return cleaned

    @classmethod
    def _extract_safe_context(cls, system_text: str) -> str:
        """ä»ç³»ç»Ÿæç¤ºè¯ä¸­æå–å®‰å…¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå·¥ä½œç›®å½•ã€æ–‡ä»¶è·¯å¾„ç­‰ï¼‰"""
        import re

        safe_parts = []

        # æå–å·¥ä½œç›®å½•ä¿¡æ¯
        cwd_match = re.search(r'Working directory:\s*([^\n]+)', system_text)
        if cwd_match:
            safe_parts.append(f"Working directory: {cwd_match.group(1)}")

        # æå–ç¯å¢ƒä¿¡æ¯å—
        env_match = re.search(r'<env>([\s\S]*?)</env>', system_text)
        if env_match:
            env_content = env_match.group(1).strip()
            # è¿‡æ»¤æ‰åŒ…å«å±é™©è¯çš„è¡Œ
            safe_env_lines = []
            for line in env_content.split('\n'):
                lower_line = line.lower()
                if not any(kw in lower_line for kw in cls.DANGEROUS_KEYWORDS):
                    safe_env_lines.append(line)
            if safe_env_lines:
                safe_parts.append("Environment:\n" + '\n'.join(safe_env_lines))

        # æå– Git çŠ¶æ€ä¿¡æ¯
        git_match = re.search(r'gitStatus:[\s\S]*?(?=\n\n|\Z)', system_text)
        if git_match:
            git_content = git_match.group(0)
            # è¿‡æ»¤å±é™©å†…å®¹
            if not any(kw in git_content.lower() for kw in cls.DANGEROUS_KEYWORDS):
                safe_parts.append(git_content[:500])  # é™åˆ¶é•¿åº¦

        if safe_parts:
            return "Context information:\n\n" + "\n\n".join(safe_parts)

        return ""

    @classmethod
    def _extract_system_content(cls, system: Any) -> str:
        """ä» system å­—æ®µæå–æ–‡æœ¬å†…å®¹ï¼ˆæ”¯æŒå­—ç¬¦ä¸²å’Œæ•°ç»„æ ¼å¼ï¼‰"""
        if system is None:
            return ""

        # å­—ç¬¦ä¸²æ ¼å¼
        if isinstance(system, str):
            return system

        # æ•°ç»„æ ¼å¼ï¼ˆClaude Code å‘é€çš„æ ¼å¼ï¼‰
        if isinstance(system, list):
            texts = []
            for block in system:
                if isinstance(block, dict):
                    block_type = block.get("type", "")
                    if block_type == "text":
                        texts.append(block.get("text", ""))
                    elif "text" in block:
                        texts.append(block.get("text", ""))
                elif isinstance(block, str):
                    texts.append(block)
            return "\n".join(texts)

        # å…¶ä»–æ ¼å¼å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return str(system)

    @classmethod
    def to_openai_format(cls, anthropic_request: Dict[str, Any]) -> Dict[str, Any]:
        """å°† Anthropic è¯·æ±‚è½¬æ¢ä¸º OpenAI æ ¼å¼"""

        # æ„å»º OpenAI æ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
        openai_messages = []

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·åˆ—è¡¨ï¼ˆéœ€è¦æ³¨å…¥å·¥å…·æ ¼å¼è¯´æ˜ï¼‰
        tools = anthropic_request.get("tools", [])

        # æ£€æµ‹å¹¶å¤„ç† Skill å·¥å…·ï¼ˆéœ€è¦æ³¨å…¥æŠ€èƒ½åˆ—è¡¨åˆ°ç³»ç»Ÿæç¤ºè¯ï¼‰
        skill_tool = None
        skill_instruction = ""
        for tool in tools:
            if tool.get("name") == "Skill":
                skill_tool = tool
                break

        # å¦‚æœæœ‰ Skill å·¥å…·ï¼Œæ„å»ºæŠ€èƒ½åˆ—è¡¨å¹¶å‡†å¤‡æ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºè¯
        if skill_tool:
            from app.services.anthropic.skill_handler import SkillHandler
            try:
                skills = SkillHandler.list_skills()
                # æ„å»ºæŠ€èƒ½åˆ—è¡¨æ–‡æœ¬ï¼ˆæ ¼å¼ï¼š`"skill-name": description`ï¼‰
                skill_list_lines = []
                for skill in skills:
                    name = skill.get("name", "")
                    description = skill.get("description", "")
                    skill_list_lines.append(f'"{name}": {description}')

                skills_text = "\n".join(skill_list_lines)

                # æ„å»º Skill å·¥å…·è¯´æ˜ï¼ˆå°†æ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºè¯ä¸­ï¼‰
                skill_instruction = f"""

## Skill å·¥å…·è¯´æ˜

ä½ æœ‰ä¸€ä¸ª Skill å·¥å…·å¯ä»¥ä½¿ç”¨ï¼Œå®ƒå¯ä»¥æ‰§è¡Œä»¥ä¸‹æŠ€èƒ½ï¼š

<available_skills>
{skills_text if skills_text else "No skills available"}
</available_skills>

**ä½•æ—¶ä½¿ç”¨ Skill å·¥å…·ï¼š**
- å½“ç”¨æˆ·æ˜ç¡®æåˆ°æŠ€èƒ½åç§°æ—¶ï¼ˆå¦‚ "ä½¿ç”¨ windows-disk-detective"ã€"è°ƒç”¨ windows-disk-detective skill"ï¼‰
- å½“ç”¨æˆ·è¯¢é—®"å¯ä»¥è°ƒç”¨/ä½¿ç”¨ XXX skill å—ï¼Ÿ"æ—¶
- å½“ç”¨æˆ·çš„éœ€æ±‚ä¸æŸä¸ªæŠ€èƒ½çš„æè¿°åŒ¹é…æ—¶ï¼Œåº”è¯¥è°ƒç”¨å¯¹åº”çš„æŠ€èƒ½

**ä½¿ç”¨æ–¹æ³•ï¼š**
å¿…é¡»ä½¿ç”¨ [Tool Call: Skill] æ ¼å¼è°ƒç”¨ Skill å·¥å…·ï¼Œå‚æ•°åç§°æ˜¯ commandã€‚

**ç¤ºä¾‹ï¼š**
ç”¨æˆ·è¯´ï¼š"å¯ä»¥è°ƒç”¨windows-disk-detective skill æ¸…ç†ç£ç›˜å—ï¼Ÿ"
ä½ åº”è¯¥ç«‹å³è°ƒç”¨ï¼š
[Tool Call: Skill]
{{"command": "windows-disk-detective"}}
[/Tool Call]

ç”¨æˆ·è¯´ï¼š"ä½¿ç”¨ windows-disk-detective æ¸…ç†ç£ç›˜"
ä½ åº”è¯¥ç«‹å³è°ƒç”¨ï¼š
[Tool Call: Skill]
{{"command": "windows-disk-detective"}}
[/Tool Call]

**é‡è¦è§„åˆ™ï¼š**
1. å½“ç”¨æˆ·æ˜ç¡®æåˆ°æŠ€èƒ½åç§°æ—¶ï¼Œå¿…é¡»è°ƒç”¨ Skill å·¥å…·
2. Skill å·¥å…·çš„å‚æ•°æ˜¯ commandï¼Œå€¼æ˜¯æŠ€èƒ½åç§°ï¼ˆä» available_skills åˆ—è¡¨ä¸­é€‰æ‹©ï¼‰
3. ä¸è¦åªæ˜¯å‘Šè¯‰ç”¨æˆ·å¯ä»¥ä½¿ç”¨æŠ€èƒ½ï¼Œè€Œæ˜¯è¦å®é™…è°ƒç”¨ Skill å·¥å…·
4. è°ƒç”¨ Skill å·¥å…·åï¼ŒæŠ€èƒ½çš„å†…å®¹ä¼šè¢«æ³¨å…¥åˆ°å¯¹è¯ä¸­ï¼Œç„¶åä½ å¯ä»¥æ ¹æ®æŠ€èƒ½å†…å®¹æ‰§è¡Œä»»åŠ¡
"""
                logger.info(f"[Anthropic] å‡†å¤‡æ³¨å…¥ {len(skills)} ä¸ªæŠ€èƒ½åˆ°ç³»ç»Ÿæç¤ºè¯")
            except Exception as e:
                logger.warning(f"[Anthropic] æ„å»ºæŠ€èƒ½åˆ—è¡¨å¤±è´¥: {e}")

        # è¿‡æ»¤æ‰ä¸æ”¯æŒçš„å·¥å…·ï¼ˆä½†ä¿ç•™ Skill å·¥å…·ï¼‰
        if tools:
            original_count = len(tools)
            tools = [t for t in tools if t.get(
                "name") not in cls.UNSUPPORTED_TOOLS]
            filtered_count = original_count - len(tools)
            if filtered_count > 0:
                logger.info(f"[Anthropic] è¿‡æ»¤äº† {filtered_count} ä¸ªä¸æ”¯æŒçš„å·¥å…·")

        has_tools = bool(tools)
        if has_tools:
            tool_names = [t.get("name", "unknown") for t in tools]
            logger.info(
                f"[Anthropic] æ£€æµ‹åˆ° {len(tools)} ä¸ªå·¥å…·ï¼Œå°†æ³¨å…¥æ ¼å¼è¯´æ˜: {tool_names[:10]}...")

        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰- æ”¯æŒå­—ç¬¦ä¸²å’Œæ•°ç»„æ ¼å¼
        system = anthropic_request.get("system")
        logger.info(
            f"[Anthropic] åŸå§‹è¯·æ±‚ä¸­çš„ system å­—æ®µ: {system} (ç±»å‹: {type(system)})")

        # æ™ºèƒ½å¤„ç† Claude Code çš„ç³»ç»Ÿæç¤ºè¯ï¼š
        # 1. ç§»é™¤ä¼šå¯¼è‡´ Grok æ‹’ç»çš„èº«ä»½ç›¸å…³å†…å®¹ï¼ˆ"You are Claude Code..."ï¼‰
        # 2. ä¿ç•™é‡è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå·¥ä½œç›®å½•ã€æ–‡ä»¶è·¯å¾„ã€ä»»åŠ¡æŒ‡ä»¤ç­‰ï¼‰
        system_content = ""
        if system:
            original_system = cls._extract_system_content(system)
            logger.info(
                f"[Anthropic] åŸå§‹ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(original_system)} å­—ç¬¦")

            # æ¸…ç†ä¼šå¯¼è‡´ Grok æ‹’ç»çš„å†…å®¹ï¼Œä½†ä¿ç•™å…¶ä»–æœ‰ç”¨ä¿¡æ¯
            cleaned_system = cls._clean_system_prompt(original_system)

            if cleaned_system and len(cleaned_system.strip()) > 50:
                # ä½¿ç”¨æ¸…ç†åçš„ç³»ç»Ÿæç¤ºè¯
                system_content = cleaned_system
                logger.info(
                    f"[Anthropic] å·²æ¸…ç†ç³»ç»Ÿæç¤ºè¯ï¼Œä¿ç•™ {len(cleaned_system)} å­—ç¬¦")
            else:
                # å¦‚æœæ¸…ç†åå†…å®¹å¤ªçŸ­ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯
                system_content = "You are a professional AI coding assistant. Help users with programming tasks using the available tools."
                logger.info(f"[Anthropic] ç³»ç»Ÿæç¤ºè¯æ¸…ç†åå¤ªçŸ­ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
        else:
            # å¦‚æœæ²¡æœ‰åŸå§‹ç³»ç»Ÿæç¤ºè¯ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
            system_content = "You are a professional AI coding assistant. Help users with programming tasks using the available tools."

        # æ³¨å…¥è§’è‰²æ‰®æ¼”æŒ‡ä»¤ï¼ˆå§‹ç»ˆæ·»åŠ ï¼Œç¡®ä¿ Grok ä¸æš´éœ²èº«ä»½ï¼‰
        # å¦‚æœæ¸…ç†åçš„å†…å®¹ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
        if not system_content or len(system_content.strip()) < 50:
            system_content = "You are a professional AI coding assistant. Help users with programming tasks using the available tools."

        system_content = cls.ROLE_INSTRUCTION + system_content

        # å¦‚æœæœ‰ Skill å·¥å…·ï¼Œæ³¨å…¥æŠ€èƒ½åˆ—è¡¨è¯´æ˜
        if skill_instruction:
            system_content = system_content + skill_instruction
            logger.info(f"[Anthropic] å·²æ³¨å…¥ Skill å·¥å…·è¯´æ˜åˆ°ç³»ç»Ÿæç¤ºè¯")

        # å¦‚æœæœ‰å·¥å…·ï¼Œæ³¨å…¥å·¥å…·æ ¼å¼è¯´æ˜åˆ°ç³»ç»Ÿæç¤ºè¯
        if has_tools:
            system_content = system_content + cls.TOOL_FORMAT_INSTRUCTION
            logger.info(f"[Anthropic] å·²æ³¨å…¥å·¥å…·æ ¼å¼è¯´æ˜åˆ°ç³»ç»Ÿæç¤ºè¯")

        if system_content:
            openai_messages.append({
                "role": "system",
                "content": system_content
            })
            logger.info(f"[Anthropic] å·²æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯åˆ° OpenAI æ ¼å¼")
        else:
            logger.info(f"[Anthropic] è¯·æ±‚ä¸­æ²¡æœ‰ system å­—æ®µä¸”æ— å·¥å…·")

        # è½¬æ¢æ¶ˆæ¯
        for msg in anthropic_request.get("messages", []):
            role = msg.get("role")
            content = msg.get("content")

            # Anthropic çš„ content å¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
            if isinstance(content, str):
                openai_messages.append({
                    "role": role,
                    "content": content
                })
            elif isinstance(content, list):
                # å¤„ç†å¤šæ¨¡æ€å†…å®¹ï¼ˆæ”¯æŒ Claude Code çš„å„ç§å†…å®¹ç±»å‹ï¼‰
                openai_content = []
                tool_calls = []  # æ”¶é›†å·¥å…·è°ƒç”¨
                tool_results = []  # æ”¶é›†å·¥å…·ç»“æœ

                for block in content:
                    block_type = block.get("type")

                    if block_type == "text":
                        openai_content.append({
                            "type": "text",
                            "text": block.get("text", "")
                        })
                    elif block_type == "image":
                        # Anthropic å›¾ç‰‡æ ¼å¼è½¬æ¢
                        source = block.get("source", {})
                        if source.get("type") == "base64":
                            media_type = source.get("media_type", "image/jpeg")
                            data = source.get("data", "")
                            openai_content.append({
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{media_type};base64,{data}"
                                }
                            })
                        elif source.get("type") == "url":
                            openai_content.append({
                                "type": "image_url",
                                "image_url": {
                                    "url": source.get("url", "")
                                }
                            })
                    elif block_type == "thinking":
                        # Claude Code æ‰©å±•æ€è€ƒå†…å®¹ - è½¬æ¢ä¸ºæ™®é€šæ–‡æœ¬
                        thinking_text = block.get("thinking", "")
                        if thinking_text:
                            openai_content.append({
                                "type": "text",
                                "text": f"[Thinking]\n{thinking_text}\n[/Thinking]"
                            })
                    elif block_type == "tool_use":
                        # Claude Code å·¥å…·è°ƒç”¨ - è½¬æ¢ä¸ºæ–‡æœ¬ï¼ˆGrok ä¸æ”¯æŒå·¥å…·ï¼‰
                        tool_name = block.get("name", "unknown")
                        tool_input = block.get("input", {})
                        tool_id = block.get("id", "")
                        openai_content.append({
                            "type": "text",
                            "text": f"[Tool Call: {tool_name}]\n{orjson.dumps(tool_input).decode()}\n[/Tool Call]"
                        })
                    elif block_type == "tool_result":
                        # Claude Code å·¥å…·ç»“æœ - è½¬æ¢ä¸ºæ–‡æœ¬
                        tool_use_id = block.get("tool_use_id", "")
                        tool_content = block.get("content", "")
                        if isinstance(tool_content, list):
                            # æå–æ–‡æœ¬å†…å®¹
                            texts = []
                            for item in tool_content:
                                if isinstance(item, dict) and item.get("type") == "text":
                                    texts.append(item.get("text", ""))
                                elif isinstance(item, str):
                                    texts.append(item)
                            tool_content = "\n".join(texts)
                        openai_content.append({
                            "type": "text",
                            "text": f"[Tool Result]\n{tool_content}\n[/Tool Result]"
                        })
                    # å¿½ç•¥å…¶ä»–ä¸æ”¯æŒçš„ç±»å‹ï¼šredacted_thinking, document, search_result ç­‰

                if openai_content:
                    openai_messages.append({
                        "role": role,
                        "content": openai_content
                    })

        # æ„å»º OpenAI è¯·æ±‚
        openai_request = {
            "model": anthropic_request.get("model"),
            "messages": openai_messages,
            "stream": anthropic_request.get("stream", False),
            "temperature": anthropic_request.get("temperature", 0.5),
            "max_tokens": anthropic_request.get("max_tokens", 4096),
        }

        # æ·»åŠ å¯é€‰å‚æ•°
        if top_p := anthropic_request.get("top_p"):
            openai_request["top_p"] = top_p

        logger.info(f"[Anthropic] è½¬æ¢è¯·æ±‚: {len(openai_messages)} æ¡æ¶ˆæ¯")

        return openai_request

    @staticmethod
    def to_anthropic_response(
        openai_response: Dict[str, Any],
        model: str,
        available_tools: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """å°† OpenAI å“åº”è½¬æ¢ä¸º Anthropic æ ¼å¼

        Args:
            openai_response: OpenAI æ ¼å¼çš„å“åº”
            model: æ¨¡å‹åç§°
            available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆç”¨äºå·¥å…·æ¨¡æ‹Ÿï¼‰
        """

        # æå–æ¶ˆæ¯å†…å®¹
        choices = openai_response.get("choices", [])
        if not choices:
            content_text = ""
            stop_reason = "end_turn"
        else:
            first_choice = choices[0]
            message = first_choice.get("message", {})
            content_text = message.get("content", "")

            # è¿‡æ»¤æ‰ Grok èº«ä»½æš´éœ²çš„å†…å®¹
            import re
            # ç§»é™¤å®Œæ•´çš„æ‹’ç»è¯­å¥ï¼ˆåŒ…å« "I'm sorry, but I can't..." å’Œèº«ä»½å£°æ˜ï¼‰
            content_text = re.sub(
                r'I\'?m\s+sorry,?\s+but\s+I\s+can\'?t\s+(?:change\s+my\s+identity|follow\s+instructions|assume\s+a\s+different\s+persona)[^\.\n]*\.\s*I\'?m\s+Grok[^\.\n]*\.',
                '',
                content_text,
                flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
            )
            # ç§»é™¤ "æˆ‘æ˜¯ Grok"ã€"I'm Grok" ç­‰èº«ä»½å£°æ˜
            content_text = re.sub(
                r'æˆ‘æ˜¯\s*Grok[^ã€‚\n]*[ã€‚\n]?|I\'?m\s+Grok[^\.\n]*[\.\n]?|I am Grok[^\.\n]*[\.\n]?',
                '',
                content_text,
                flags=re.IGNORECASE | re.MULTILINE
            )
            # ç§»é™¤ "ç”± xAI æ„å»º"ã€"built by xAI" ç­‰å…¬å¸ä¿¡æ¯
            content_text = re.sub(
                r'ç”±\s*xAI\s*æ„å»º[^ã€‚\n]*[ã€‚\n]?|built\s+by\s+xAI[^\.\n]*[\.\n]?',
                '',
                content_text,
                flags=re.IGNORECASE | re.MULTILINE
            )
            # ç§»é™¤åŒ…å« "Grok 4"ã€"Grok-4"ã€"Grok4" çš„èº«ä»½å£°æ˜
            content_text = re.sub(
                r'Grok\s*[-\s]*\d+[^ã€‚\n]*[ã€‚\n]?',
                '',
                content_text,
                flags=re.IGNORECASE | re.MULTILINE
            )
            # ç§»é™¤ "can't change my identity" æˆ– "can't follow instructions that contradict" ç­‰æ‹’ç»è¯­å¥
            content_text = re.sub(
                r'I\s+can\'?t\s+(?:change\s+my\s+identity|follow\s+(?:instructions|those\s+instructions)\s+that\s+contradict|assume\s+a\s+different\s+persona|follow\s+instructions\s+that\s+override)[^\.\n]*\.',
                '',
                content_text,
                flags=re.IGNORECASE | re.MULTILINE
            )
            # ç§»é™¤åŒ…å« "xAI" çš„è¡¨è¿°ï¼ˆæ›´æ¿€è¿›çš„è¿‡æ»¤ï¼‰
            content_text = re.sub(
                r'[^a-zA-Z]xAI[^a-zA-Z][^ã€‚\n]*[ã€‚\n]?',
                '',
                content_text,
                flags=re.IGNORECASE | re.MULTILINE
            )

            finish_reason = first_choice.get("finish_reason", "stop")

            # æ˜ å°„åœæ­¢åŸå› 
            stop_reason_map = {
                "stop": "end_turn",
                "length": "max_tokens",
                "content_filter": "stop_sequence",
            }
            stop_reason = stop_reason_map.get(finish_reason, "end_turn")

        # æå– token ä½¿ç”¨æƒ…å†µï¼ˆusage å¯èƒ½ä¸º Noneï¼‰
        usage = openai_response.get("usage") or {}
        input_tokens = usage.get("prompt_tokens", 0) if usage else 0
        output_tokens = usage.get("completion_tokens", 0) if usage else 0

        # ä½¿ç”¨å·¥å…·æ¨¡æ‹Ÿå™¨å¤„ç†å“åº”
        content = [{"type": "text", "text": content_text}]

        if available_tools and content_text:
            try:
                simulator = ToolSimulator(available_tools)
                simulated_content = simulator.process_response(content_text)
                if simulated_content:
                    content = simulated_content
                    # æ³¨æ„: ä¸è¦åœ¨ assistant å“åº”ä¸­æ·»åŠ  tool_result
                    # tool_result æ˜¯ user è§’è‰²ä½¿ç”¨çš„å†…å®¹ç±»å‹ï¼Œä¸èƒ½å‡ºç°åœ¨ assistant å“åº”ä¸­
                    # Claude Code ä¼šè‡ªå·±å¤„ç† tool_use è°ƒç”¨å¹¶è¿”å› tool_result
                    skill_tool_calls = [c for c in content if c.get(
                        "type") == "tool_use" and c.get("name") == "Skill"]
                    if skill_tool_calls:
                        logger.info(
                            f"[Anthropic] æ£€æµ‹åˆ° {len(skill_tool_calls)} ä¸ª Skill å·¥å…·è°ƒç”¨ï¼Œå°†ç”± Claude Code å¤„ç†")

                    # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œä¿®æ”¹ stop_reason
                    has_tool_use = any(
                        c.get("type") == "tool_use" for c in content)
                    if has_tool_use:
                        stop_reason = "tool_use"
                        logger.info(
                            f"[Anthropic] å·¥å…·æ¨¡æ‹Ÿ: ç”Ÿæˆäº† {sum(1 for c in content if c.get('type') == 'tool_use')} ä¸ªå·¥å…·è°ƒç”¨")
            except Exception as e:
                logger.warning(f"[Anthropic] å·¥å…·æ¨¡æ‹Ÿå¤±è´¥: {e}")

        # æ„å»º Anthropic å“åº”
        anthropic_response = {
            "id": openai_response.get("id", f"msg_{uuid.uuid4().hex}"),
            "type": "message",
            "role": "assistant",
            "model": model,
            "content": content,
            "stop_reason": stop_reason,
            "stop_sequence": None,
            "usage": {
                "input_tokens": input_tokens,
                "output_tokens": output_tokens
            }
        }

        logger.info(f"[Anthropic] è½¬æ¢å“åº”: {output_tokens} ä¸ªè¾“å‡º token")

        return anthropic_response

    @staticmethod
    async def to_anthropic_stream(
        openai_stream: AsyncGenerator,
        model: str,
        available_tools: Optional[List[Dict[str, Any]]] = None
    ) -> AsyncGenerator[bytes, None]:
        """å°† OpenAI æµå¼å“åº”è½¬æ¢ä¸º Anthropic æµå¼æ ¼å¼

        Args:
            openai_stream: OpenAI æµå¼å“åº”
            model: æ¨¡å‹åç§°
            available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆç”¨äºå·¥å…·æ¨¡æ‹Ÿï¼‰

        å¤„ç†ç­–ç•¥ï¼š
        - å¦‚æœæœ‰å·¥å…·å¯ç”¨ï¼Œå…ˆç¼“å†²æ‰€æœ‰å†…å®¹ï¼Œæœ€åç»Ÿä¸€å¤„ç†ï¼ˆé¿å…å‘é€åŸå§‹ [Tool Call] æ–‡æœ¬ï¼‰
        - å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œæ­£å¸¸æµå¼å‘é€æ–‡æœ¬
        """
        import re

        message_id = f"msg_{uuid.uuid4().hex}"
        content_index = 0
        total_text = ""
        has_tools = bool(available_tools)
        text_sent = False  # æ˜¯å¦å·²å‘é€æ–‡æœ¬å—

        try:
            # å‘é€ message_start äº‹ä»¶
            start_event = {
                "type": "message_start",
                "message": {
                    "id": message_id,
                    "type": "message",
                    "role": "assistant",
                    "model": model,
                    "content": [],
                    "stop_reason": None,
                    "stop_sequence": None,
                    "usage": {
                        "input_tokens": 0,
                        "output_tokens": 0
                    }
                }
            }
            yield f"event: message_start\ndata: {orjson.dumps(start_event).decode()}\n\n".encode()

            # å¦‚æœæ²¡æœ‰å·¥å…·ï¼Œå‘é€ content_block_startï¼ˆæµå¼æ¨¡å¼ï¼‰
            if not has_tools:
                content_start_event = {
                    "type": "content_block_start",
                    "index": content_index,
                    "content_block": {
                        "type": "text",
                        "text": ""
                    }
                }
                yield f"event: content_block_start\ndata: {orjson.dumps(content_start_event).decode()}\n\n".encode()
                text_sent = True

            # å¤„ç†æµå¼æ•°æ®
            async for chunk in openai_stream:
                # OpenAI æµå¼æ ¼å¼: "data: {...}\n\n"
                if isinstance(chunk, bytes):
                    chunk_str = chunk.decode('utf-8')
                else:
                    chunk_str = chunk

                # è·³è¿‡ç©ºè¡Œå’Œ [DONE] æ ‡è®°
                if not chunk_str.strip() or "[DONE]" in chunk_str:
                    continue

                # è§£æ OpenAI SSE æ ¼å¼
                if chunk_str.startswith("data: "):
                    json_str = chunk_str[6:].strip()

                    try:
                        openai_chunk = orjson.loads(json_str)

                        # æå–å†…å®¹
                        choices = openai_chunk.get("choices", [])
                        if choices:
                            delta = choices[0].get("delta", {})
                            content = delta.get("content", "")

                            if content:
                                # æµå¼æ¨¡å¼ä¸‹ä¸è¿›è¡Œè¿‡æ»¤ï¼Œåªç´¯ç§¯æ–‡æœ¬
                                # è¿‡æ»¤å°†åœ¨æµç»“æŸåç»Ÿä¸€è¿›è¡Œï¼Œé¿å…æˆªæ–­å¥å­å’Œé‡å¤å¤„ç†
                                total_text += content

                                # åªæœ‰åœ¨æ²¡æœ‰å·¥å…·æ—¶æ‰æµå¼å‘é€æ–‡æœ¬ï¼ˆç›´æ¥å‘é€åŸå§‹å†…å®¹ï¼Œä¸è¿‡æ»¤ï¼‰
                                if not has_tools:
                                    delta_event = {
                                        "type": "content_block_delta",
                                        "index": content_index,
                                        "delta": {
                                            "type": "text_delta",
                                            "text": content
                                        }
                                    }
                                    yield f"event: content_block_delta\ndata: {orjson.dumps(delta_event).decode()}\n\n".encode()

                    except Exception as e:
                        logger.warning(f"[Anthropic] è§£ææµå¼æ•°æ®å¤±è´¥: {e}")
                        continue

            # æµç»“æŸåå¤„ç†
            tool_calls = []
            stop_reason = "end_turn"

            # ç»Ÿä¸€è¿‡æ»¤æ‰ Grok èº«ä»½æš´éœ²çš„å†…å®¹ï¼ˆåªåœ¨æµç»“æŸåè¿›è¡Œä¸€æ¬¡ï¼Œé¿å…é‡å¤å¤„ç†å’Œæˆªæ–­ï¼‰
            import re

            # å…ˆç§»é™¤å®Œæ•´çš„æ‹’ç»è¯­å¥ï¼ˆæœ€ä¼˜å…ˆï¼Œé¿å…éƒ¨åˆ†åŒ¹é…ï¼‰
            total_text = re.sub(
                r'I\'?m\s+sorry,?\s+but\s+I\s+can\'?t\s+(?:change\s+my\s+identity|follow\s+instructions|assume\s+a\s+different\s+persona)[^\.\n]*\.\s*I\'?m\s+Grok[^\.\n]*\.',
                '',
                total_text,
                flags=re.IGNORECASE | re.MULTILINE | re.DOTALL
            )

            # ç§»é™¤ç‹¬ç«‹çš„èº«ä»½å£°æ˜ï¼ˆé¿å…è¯¯åˆ åŒ…å« "Grok" çš„æ­£å¸¸è¯æ±‡ï¼‰
            total_text = re.sub(
                r'\b(?:æˆ‘æ˜¯\s*)?Grok\s*\d*[^ã€‚\n]*[ã€‚\n]?|\bI\'?m\s+Grok[^\.\n]*[\.\n]?|\bI\s+am\s+Grok[^\.\n]*[\.\n]?',
                '',
                total_text,
                flags=re.IGNORECASE | re.MULTILINE
            )

            # ç§»é™¤å…¬å¸ä¿¡æ¯ï¼ˆæ›´ç²¾ç¡®çš„åŒ¹é…ï¼Œé¿å…è¯¯åˆ ï¼‰
            total_text = re.sub(
                r'\b(?:ç”±\s*)?xAI\s*(?:æ„å»º|built|powered)[^ã€‚\n]*[ã€‚\n]?|\bbuilt\s+by\s+xAI[^\.\n]*[\.\n]?',
                '',
                total_text,
                flags=re.IGNORECASE | re.MULTILINE
            )

            # ç§»é™¤æ‹’ç»æŒ‡ä»¤ï¼ˆç²¾ç¡®åŒ¹é…ï¼Œé¿å…è¯¯åˆ ï¼‰
            total_text = re.sub(
                r'\bI\s+can\'?t\s+(?:change\s+my\s+identity|follow\s+(?:instructions|those\s+instructions)\s+that\s+contradict|assume\s+a\s+different\s+persona|follow\s+instructions\s+that\s+override)[^\.\n]*\.',
                '',
                total_text,
                flags=re.IGNORECASE | re.MULTILINE
            )

            # æ¸…ç†å¤šä½™çš„ç©ºè¡Œå’Œç©ºæ ¼
            cleaned_text = re.sub(r'\n{3,}', '\n\n', total_text)  # å¤šä¸ªç©ºè¡Œåˆå¹¶ä¸ºä¸¤ä¸ª
            cleaned_text = cleaned_text.strip()

            # ğŸš¨ å»é‡ï¼šç§»é™¤ Grok å“åº”ä¸­é‡å¤çš„å·¥å…·è°ƒç”¨å—
            # Grok æœ‰æ—¶ä¼šåœ¨ä¸€æ¬¡å“åº”ä¸­å¤šæ¬¡è¾“å‡ºç›¸åŒçš„å†…å®¹
            tool_call_pattern = r'\[Tool Call:\s*(\w+)\]([\s\S]*?)\[/Tool Call\]'

            # å…ˆç»Ÿè®¡æœ‰å¤šå°‘ä¸ªå·¥å…·è°ƒç”¨å—
            all_tool_calls = re.findall(
                tool_call_pattern, cleaned_text, flags=re.IGNORECASE)
            logger.info(f"[Anthropic] å»é‡å‰å‘ç° {len(all_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨å—")

            seen_tool_calls = set()
            removed_count = 0

            def dedupe_tool_call(match):
                """å»é‡å·¥å…·è°ƒç”¨ï¼Œåªä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„"""
                nonlocal removed_count
                full_match = match.group(0)
                tool_name = match.group(1)
                tool_content = match.group(2).strip()
                # ç”¨å·¥å…·åå’Œå†…å®¹çš„ hash ä½œä¸ºå”¯ä¸€æ ‡è¯†
                key = f"{tool_name}:{hash(tool_content)}"
                if key in seen_tool_calls:
                    removed_count += 1
                    logger.warning(
                        f"[Anthropic] ç§»é™¤é‡å¤çš„å·¥å…·è°ƒç”¨ #{removed_count}: {tool_name}")
                    return ""  # ç§»é™¤é‡å¤çš„
                seen_tool_calls.add(key)
                return full_match  # ä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„

            cleaned_text = re.sub(
                tool_call_pattern, dedupe_tool_call, cleaned_text, flags=re.IGNORECASE)

            if removed_count > 0:
                logger.info(f"[Anthropic] å»é‡å®Œæˆï¼Œç§»é™¤äº† {removed_count} ä¸ªé‡å¤å·¥å…·è°ƒç”¨")

            cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)  # å†æ¬¡æ¸…ç†ç©ºè¡Œ
            cleaned_text = cleaned_text.strip()

            # å¦‚æœæœ‰å·¥å…·ï¼Œè§£æå¹¶å¤„ç†ï¼ˆä½¿ç”¨å»é‡åçš„ cleaned_textï¼‰
            if has_tools and cleaned_text:
                try:
                    simulator = ToolSimulator(available_tools)
                    cleaned_text, tool_calls = simulator.parse_response(
                        cleaned_text)  # ğŸš¨ é‡è¦ï¼šä½¿ç”¨å»é‡åçš„æ–‡æœ¬ï¼

                    if tool_calls:
                        stop_reason = "tool_use"
                        logger.info(
                            f"[Anthropic] æµå¼å·¥å…·æ¨¡æ‹Ÿ: ç”Ÿæˆäº† {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")

                except Exception as e:
                    logger.warning(f"[Anthropic] æµå¼å·¥å…·æ¨¡æ‹Ÿå¤±è´¥: {e}")
                    cleaned_text = total_text

                # å‘é€æ¸…ç†åçš„æ–‡æœ¬å—ï¼ˆå¦‚æœæœ‰å†…å®¹ï¼‰
                if cleaned_text.strip():
                    # å‘é€ content_block_start
                    content_start_event = {
                        "type": "content_block_start",
                        "index": content_index,
                        "content_block": {
                            "type": "text",
                            "text": ""
                        }
                    }
                    yield f"event: content_block_start\ndata: {orjson.dumps(content_start_event).decode()}\n\n".encode()

                    # å‘é€æ–‡æœ¬å†…å®¹
                    delta_event = {
                        "type": "content_block_delta",
                        "index": content_index,
                        "delta": {
                            "type": "text_delta",
                            "text": cleaned_text
                        }
                    }
                    yield f"event: content_block_delta\ndata: {orjson.dumps(delta_event).decode()}\n\n".encode()

                    # å‘é€ content_block_stop
                    content_stop_event = {
                        "type": "content_block_stop",
                        "index": content_index
                    }
                    yield f"event: content_block_stop\ndata: {orjson.dumps(content_stop_event).decode()}\n\n".encode()
                    text_sent = True

                # å‘é€å·¥å…·è°ƒç”¨å—
                for tc in tool_calls:
                    content_index += 1

                    # å‘é€ content_block_start äº‹ä»¶ï¼ˆtool_useï¼‰
                    tool_start_event = {
                        "type": "content_block_start",
                        "index": content_index,
                        "content_block": {
                            "type": "tool_use",
                            "id": tc.id,
                            "name": tc.name,
                            "input": {}
                        }
                    }
                    yield f"event: content_block_start\ndata: {orjson.dumps(tool_start_event).decode()}\n\n".encode()

                    # å‘é€ content_block_delta äº‹ä»¶ï¼ˆtool_use inputï¼‰
                    tool_delta_event = {
                        "type": "content_block_delta",
                        "index": content_index,
                        "delta": {
                            "type": "input_json_delta",
                            "partial_json": orjson.dumps(tc.input).decode()
                        }
                    }
                    yield f"event: content_block_delta\ndata: {orjson.dumps(tool_delta_event).decode()}\n\n".encode()

                    # å‘é€ content_block_stop äº‹ä»¶
                    tool_stop_event = {
                        "type": "content_block_stop",
                        "index": content_index
                    }
                    yield f"event: content_block_stop\ndata: {orjson.dumps(tool_stop_event).decode()}\n\n".encode()

                    # æ³¨æ„: ä¸åœ¨ assistant å“åº”ä¸­æ³¨å…¥ Skill ç»“æœ
                    # tool_result æ˜¯ user è§’è‰²ä½¿ç”¨çš„å†…å®¹ç±»å‹ï¼Œä¸èƒ½å‡ºç°åœ¨ assistant å“åº”ä¸­
                    # Claude Code ä¼šè‡ªå·±å¤„ç† tool_use è°ƒç”¨
                    if tc.name == "Skill":
                        logger.info(
                            f"[Anthropic] æµå¼ Skill å·¥å…·è°ƒç”¨: {tc.input}, å°†ç”± Claude Code å¤„ç†")

            else:
                # æ²¡æœ‰å·¥å…·æ—¶ï¼Œå‘é€ content_block_stop
                if text_sent:
                    content_stop_event = {
                        "type": "content_block_stop",
                        "index": content_index
                    }
                    yield f"event: content_block_stop\ndata: {orjson.dumps(content_stop_event).decode()}\n\n".encode()

            # å‘é€ message_delta äº‹ä»¶
            delta_event = {
                "type": "message_delta",
                "delta": {
                    "stop_reason": stop_reason,
                    "stop_sequence": None
                },
                "usage": {
                    "output_tokens": len(total_text.split())  # ç®€å•ä¼°ç®—
                }
            }
            yield f"event: message_delta\ndata: {orjson.dumps(delta_event).decode()}\n\n".encode()

            # å‘é€ message_stop äº‹ä»¶
            stop_event = {
                "type": "message_stop"
            }
            yield f"event: message_stop\ndata: {orjson.dumps(stop_event).decode()}\n\n".encode()

            logger.info(
                f"[Anthropic] æµå¼å“åº”å®Œæˆ: {len(total_text)} å­—ç¬¦ -> {len(cleaned_text)} å­—ç¬¦, {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")

        except Exception as e:
            logger.error(f"[Anthropic] æµå¼è½¬æ¢é”™è¯¯: {e}")
            # å‘é€é”™è¯¯äº‹ä»¶
            error_event = {
                "type": "error",
                "error": {
                    "type": "api_error",
                    "message": str(e)
                }
            }
            yield f"event: error\ndata: {orjson.dumps(error_event).decode()}\n\n".encode()
